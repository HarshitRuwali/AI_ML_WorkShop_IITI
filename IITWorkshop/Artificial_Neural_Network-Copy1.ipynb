{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to import the data\n",
    "(xtrain, ytrain), (xtest, ytest)= mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to split the data\n",
    "(xtrain, ytrain), (xtest, ytest)= mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using in bulit library  to reduce the intensity if the image, rest the image is same.\n",
    "xtrain=tf.keras.utils.normalize(xtrain)\n",
    "xtest=tf.keras.utils.normalize(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x64c31cc50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the image the change with the change if the xtrain vlaue\n",
    "# to build now the model to predict without the use labels, we need deep learing\n",
    "\n",
    "#a=int(input('enter the value for xtrain'))\n",
    "#a=xtrian[a]\n",
    "d=xtrain[100]\n",
    "\n",
    "d.shape\n",
    "plt.imshow(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create your Artificial Neurla Network\n",
    "model=tf.keras.models.Sequential()\n",
    "#input layer\n",
    "model.add(tf.keras.layers.Flatten()) #auto conversion in single dimension\n",
    "#hidden layer\n",
    "model.add(tf.keras.layers.Dense(128,activation ='relu')) #number of neuros- number can be variable its changed with the accuracy value\n",
    "#hidden layer \n",
    "model.add(tf.keras.layers.Dense(128,activation ='relu')) #to filter the negative numbers, rectified linear unit \n",
    "#output layer \n",
    "model.add(tf.keras.layers.Dense(10, activation ='softmax')) #no of digits or number of output required, as we are working on the supervised environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross entropy for error loss\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='categrorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Error when checking model target: expected no data, but got:', array([5, 0, 4, ..., 5, 6, 8], dtype=uint8))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-ee632e5805ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2671\u001b[0m           \u001b[0mshapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2672\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2673\u001b[0;31m           exception_prefix='target')\n\u001b[0m\u001b[1;32m   2674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2675\u001b[0m       \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    303\u001b[0m       raise ValueError(\n\u001b[1;32m    304\u001b[0m           \u001b[0;34m'Error when checking model '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m           'expected no data, but got:', data)\n\u001b[0m\u001b[1;32m    306\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Error when checking model target: expected no data, but got:', array([5, 0, 4, ..., 5, 6, 8], dtype=uint8))"
     ]
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
